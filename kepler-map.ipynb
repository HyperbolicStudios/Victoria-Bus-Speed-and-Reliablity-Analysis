{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import keplergl\n",
    "\n",
    "from create_shapes import generate_lines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieve the entire timeline (as points). Used for the system and corridor maps\n",
    "def retrieve_timeline(file_limit = 1):\n",
    "    timeline = pd.DataFrame()\n",
    "    #for csv file in historical speed data/data:\n",
    "    files = os.listdir(\"historical speed data/data\")\n",
    "    file_number = 0\n",
    "    while(file_number < file_limit):\n",
    "        filename = files[file_number]\n",
    "        file_number += 1\n",
    "        if filename.endswith(\".csv\"):\n",
    "            #read csv file\n",
    "            file = pd.read_csv(\"historical speed data/data/\" + filename, dtype={\"Time\": np.int64, \"Route\": str, \"Header\": np.int64, \"Trip ID\": np.int64, \"Speed\": np.float64, \"x\": np.float64, \"y\": np.float64, \"Occupancy Status\": np.int64})\n",
    "            #append to timeline\n",
    "            timeline = pd.concat([timeline, file], ignore_index=True)\n",
    "\n",
    "    #turn into geopandas dataframe based on x and y\n",
    "    timeline = gpd.GeoDataFrame(timeline, geometry=gpd.points_from_xy(timeline.x, timeline.y))\n",
    "    timeline = timeline.set_crs(\"EPSG:4326\").to_crs(\"EPSG:26910\")\n",
    "\n",
    "    #turn 'Time' into Datetime column\n",
    "    timeline['Datetime'] = pd.to_datetime(timeline['Time'], unit='s', utc=True)\n",
    "    #convert to PST\n",
    "    timeline['Datetime'] = timeline['Datetime'].dt.tz_convert('America/Los_Angeles')\n",
    "\n",
    "    return(timeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Getting segments...\n",
      "INFO:root:Reading \"stop_times.txt\".\n",
      "INFO:root:get trips in stop_times\n",
      "INFO:root:accessing trips\n",
      "INFO:root:Reading \"routes.txt\".\n",
      "INFO:root:Start date is None. You should either specify a start date or set busiest_date to True.\n",
      "INFO:root:Reading \"trips.txt\".\n",
      "INFO:root:File \"calendar.txt\" not found.\n",
      "INFO:root:Reading \"calendar_dates.txt\".\n",
      "INFO:root:The busiest date/s of this feed or your selected date range is/are:  ['2025-05-23', '2025-06-20', '2025-06-13', '2025-06-06', '2025-06-27', '2025-05-30'] with 2997 trips.\n",
      "INFO:root:In the case that more than one busiest date was found, the first one will be considered.\n",
      "INFO:root:In this case is 2025-05-23.\n",
      "INFO:root:Reading \"stop_times.txt\".\n",
      "INFO:root:_trips is defined in stop_times\n",
      "INFO:root:Reading \"stops.txt\".\n",
      "INFO:root:computing patterns\n",
      "INFO:root:Reading \"shapes.txt\".\n",
      "INFO:root:Projecting stops onto shape...\n",
      "INFO:root:Interpolating stops onto shape...\n",
      "INFO:root:Sorting shape points and stops...\n",
      "INFO:root:segments_df: 8568, geometry: 8568\n"
     ]
    }
   ],
   "source": [
    "route_segments = generate_lines()\n",
    "timeline = retrieve_timeline()\n",
    "\n",
    "#create a buffer around each line in lines, and create a new geodataframe with the buffers\n",
    "route_segments['line_geom'] = route_segments['geometry']\n",
    "route_segments['geometry'] = route_segments.buffer(20, cap_style=2)\n",
    "route_segments['buffer_id'] = route_segments.index\n",
    "timeline['Hour'] = timeline.Datetime.dt.hour\n",
    "\n",
    "#spatial merge. Find all the points that are within buffers, and retain buffer geometry.\n",
    "timeline = gpd.sjoin(route_segments, timeline, how=\"left\", predicate=\"intersects\")\n",
    "\n",
    "timeline['geometry'] = timeline['line_geom']\n",
    "timeline = timeline[[\"Hour\", \"Speed\", \"buffer_id\", \"geometry\"]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#system speed map\n",
    "y_var = \"Speed\"\n",
    "gdf = timeline.groupby([\"buffer_id\"]).agg({\"Speed\": \"mean\", \"geometry\": \"first\"}).reset_index()\n",
    "gdf = gpd.GeoDataFrame(gdf, geometry=\"geometry\", crs=\"EPSG:26910\")\n",
    "\n",
    "gdf = gdf.to_crs(\"WGS-84\")\n",
    "gdf[y_var] = gdf[y_var].round(1)\n",
    "\n",
    "gdf['Speed Data'] = gdf[y_var]\n",
    "gdf['colour'] = np.where(gdf['Speed Data'] > 50, 50, gdf[y_var])\n",
    "gdf['Speed'] = gdf['Speed Data'].astype(str) + \" kmh\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Guide: https://docs.kepler.gl/docs/keplergl-jupyter\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57738ace60e1478b8d93bb4779dd7a50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "KeplerGl(config={'version': 'v1', 'config': {'visState': {'filters': [], 'layers': [{'id': 'nu79ugi', 'type': …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kepler_config = json.load(open(\"kepler_configs/speed_map.json\"))    \n",
    "map_1 = keplergl.KeplerGl(height=500, data={\"Speed\": gdf}, config=kepler_config)\n",
    "map_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export config\n",
    "map_config = map_1.config\n",
    "#export to kepler_configs folder\n",
    "with open(\"kepler_configs/speed_map.json\", \"w\") as f:\n",
    "    json.dump(map_config, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#system peak vs off-peak speed map\n",
    "\n",
    "gdf = timeline.pivot_table(index=[\"buffer_id\"], columns=\"Hour\", values=\"Speed\", aggfunc=\"mean\").reset_index()\n",
    "gdf = gdf.merge(timeline[[\"buffer_id\", \"geometry\"]].drop_duplicates(subset=[\"buffer_id\"]), on=\"buffer_id\", how=\"left\")\n",
    "#calculate a three-hour-window moving average to identify the peak and off-peak speeds\n",
    "for i in range(1, 22): #centres of the different windows\n",
    "    gdf[\"{}-{}-{}\".format(i-1, i, i+1)] = gdf[[i-1, i, i+1]].mean(axis=1)\n",
    "#for each row, identify the highest and lowest values of these windows\n",
    "cols_to_analyze = gdf.loc[:, \"0-1-2\":\"20-21-22\"]\n",
    "gdf['Peak'] = cols_to_analyze.min(axis=1).round(1)\n",
    "gdf['Peak Hour'] = cols_to_analyze.idxmin(axis=1)\n",
    "gdf['Off-Peak'] = cols_to_analyze.max(axis=1).round(1)\n",
    "gdf['Off-Peak Hour'] = cols_to_analyze.idxmax(axis=1)\n",
    "\n",
    "gdf['Speed Delta'] = gdf['Off-Peak'] - gdf['Peak']\n",
    "\n",
    "gdf = gdf[[\"buffer_id\", \"geometry\", \"Peak\", \"Peak Hour\", \"Off-Peak\", \"Off-Peak Hour\", \"Speed Delta\"]]\n",
    "gdf = gpd.GeoDataFrame(gdf, geometry=\"geometry\", crs=\"EPSG:26910\")\n",
    "gdf = gdf.to_crs(\"WGS-84\")\n",
    "gdf['Speed Data'] = gdf['Speed Delta'].round(1)\n",
    "gdf['colour'] = np.where(gdf['Speed Data'] > 50, 50, gdf['Speed Data'])\n",
    "gdf['Speed Delta'] = gdf['Speed Data'].astype(str) + \" km/h\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Guide: https://docs.kepler.gl/docs/keplergl-jupyter\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ea1a614cb78463f90a65f4329400e53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "KeplerGl(config={'version': 'v1', 'config': {'visState': {'filters': [], 'layers': [{'id': 'a4jvfue', 'type': …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kepler_config = json.load(open(\"kepler_configs/delta_map.json\"))\n",
    "map_2 = keplergl.KeplerGl(height=500, data={\"Speed Delta\": gdf}, config=kepler_config)\n",
    "map_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export config\n",
    "map_config = map_2.config\n",
    "#export to kepler_configs folder\n",
    "with open(\"kepler_configs/delta_map.json\", \"w\") as f:\n",
    "    json.dump(map_config, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dot map\n",
    "\n",
    "timeline = retrieve_timeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pick 150000 random points\n",
    "gdf = timeline\n",
    "if len(gdf) >= 150000:\n",
    "    gdf = gdf.sample(n=150000)\n",
    "\n",
    "#convert datetime to string\n",
    "#gdf['Datetime'] = gdf['Datetime'].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "#format in plain english\n",
    "\n",
    "gdf = gdf.drop(columns=['Time'])\n",
    "\n",
    "#round speed to 1 decimal place\n",
    "gdf.Speed = gdf.Speed.round(1)\n",
    "\n",
    "gdf['Speed Data'] = gdf['Speed'].round(1)\n",
    "gdf['colour'] = np.where(gdf['Speed Data'] > 50, 50, gdf['Speed Data'])\n",
    "gdf['Speed'] = gdf['Speed Data'].astype(str) + \" km/h\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Guide: https://docs.kepler.gl/docs/keplergl-jupyter\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bbddfe1e1e349529957e80e5769cc82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "KeplerGl(config={'version': 'v1', 'config': {'visState': {'filters': [{'dataId': ['Speed'], 'id': '5k68gnjoc',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kepler_config = json.load(open(\"kepler_configs/dot_map.json\"))\n",
    "map_1 = keplergl.KeplerGl(height=500, data={\"Speed\": gdf}, config=kepler_config)\n",
    "map_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export config\n",
    "map_config = map_1.config\n",
    "#export to kepler_configs folder\n",
    "with open(\"kepler_configs/dot_map.json\", \"w\") as f:\n",
    "    json.dump(map_config, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Map saved to docs/plots/dot_map.html!\n"
     ]
    }
   ],
   "source": [
    "# Export the Kepler.gl map as an HTML file\n",
    "map_1.save_to_html(file_name=\"docs/plots/dot_map.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corridor map\n",
    "\n",
    "corridors = gpd.read_file(\"roads/corridors.geojson\").set_crs(\"EPSG:4326\").to_crs(\"EPSG:26910\")\n",
    "\n",
    "#add names to each corridor: Mckenzie, Fort St West, Fort St East, Foul Bay, Henderson, Quadra\n",
    "corridors[\"corridor\"] = [\"Mckenzie\", \"Fort St West\", \"Fort St East\", \"Foul Bay\", \"Hillside\", \"Quadra\",\"Douglas Core\",\"Douglas North\", \"Pandora West\", \"Pandora East\", \"Shelbourne South\", \"Shelbourne North\", \"Johnson\", \"Oak Bay\"]\n",
    "corridors['Average Speed'] = 0\n",
    "timeline = retrieve_timeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_routes = {\n",
    "    \"Mckenzie\": [\"26\"],\n",
    "    \"Fort St West\": [\"14\", \"15\", \"11\"],\n",
    "    \"Fort St East\": [\"14\", \"15\", \"11\"],\n",
    "    \"Foul Bay\": [\"7\", \"15\"],\n",
    "    \"Hillside\": [\"4\"],\n",
    "    \"Quadra\": [\"6\"],\n",
    "    \"Douglas Core\": [\"95\"],\n",
    "    \"Douglas North\": [\"95\"],\n",
    "    \"Pandora West\": [\"2\", \"5\", \"27\", \"28\"],\n",
    "    \"Pandora East\": [\"2\", \"5\", \"27\", \"28\"],\n",
    "    \"Shelbourne South\": [\"27\", \"28\"],\n",
    "    \"Shelbourne North\": [\"27\", \"28\"],\n",
    "    \"Johnson\": [\"2\", \"5\", \"27\", \"28\"],\n",
    "    \"Oak Bay\": [\"2\", \"5\"]\n",
    "}\n",
    "\n",
    "#for map_name, y_var, title in [(\"system_speed_map\", \"Speed\", \"Average All-Day Speed\"), (\"system_speed_peak_map\", \"Speed\", \"Average Speed (8am-11am)\"), (\"system_peak_variability_map\", \"Speed Variability\", \"Speed Variability (8am-11am)\")]:\n",
    "\n",
    "\n",
    "for corridor in corridors.corridor:\n",
    "    filtered_timeline = timeline[timeline.Route.isin(selected_routes[corridor])].reset_index()\n",
    "    buffer = corridors[corridors.corridor == corridor].buffer(20, cap_style=2)\n",
    "    buffer = gpd.GeoDataFrame(buffer, geometry=buffer, crs=\"EPSG:26910\")\n",
    "\n",
    "    #filter timeline to only include points within buffer\n",
    "    filtered_timeline = filtered_timeline[filtered_timeline.geometry.within(buffer.unary_union)]\n",
    "\n",
    "    #calculate average speed and update corridor dataframd\n",
    "    avg_speed = filtered_timeline.Speed.mean()\n",
    "    avg_speed = round(avg_speed, 1)\n",
    "    corridors.loc[corridors.corridor == corridor, \"Average Speed\"] = avg_speed\n",
    "\n",
    "corridors = corridors.to_crs(\"EPSG:4326\")\n",
    "\n",
    "corridors['Speed Data'] = corridors['Average Speed'].round(1)\n",
    "corridors['colour'] = np.where(corridors['Speed Data'] > 50, 50, corridors['Speed Data'])\n",
    "corridors['Speed'] = corridors['Speed Data'].astype(str) + \" km/h\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Guide: https://docs.kepler.gl/docs/keplergl-jupyter\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea3bd3b185164421adb05f0cb101bcd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "KeplerGl(config={'version': 'v1', 'config': {'visState': {'filters': [], 'layers': [{'id': '7yfl0ij', 'type': …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kepler_config = json.load(open(\"kepler_configs/corridor_map.json\"))\n",
    "map_1 = keplergl.KeplerGl(height=1000, data={\"Speed\": corridors}, config=kepler_config)\n",
    "map_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = map_1.config\n",
    "#export config\n",
    "with open(\"kepler_configs/corridor_map.json\", \"w\") as f:\n",
    "    json.dump(config, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gtfs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
